{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standalone DexYCB Evaluation with Standard Metrics\n",
    "\n",
    "This notebook provides a standalone evaluation script that doesn't require the full model infrastructure.\n",
    "It loads predictions and ground truth data to compute:\n",
    "- **MPJPE**: Mean Per Joint Position Error in millimeters\n",
    "- **PA-MPJPE**: Procrustes-aligned MPJPE after optimal rigid alignment\n",
    "- **PCK**: Percentage of Correct Keypoints within various thresholds\n",
    "- **AUC**: Area Under Curve for PCK from 0-50mm\n",
    "- **Diversity**: Standard deviation of predictions to measure mode collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric computation functions\n",
    "\n",
    "def compute_mpjpe(pred_joints: np.ndarray, gt_joints: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute Mean Per Joint Position Error\n",
    "    \n",
    "    Args:\n",
    "        pred_joints: [N, 21, 3] predicted 3D joints\n",
    "        gt_joints: [N, 21, 3] ground truth 3D joints\n",
    "    \n",
    "    Returns:\n",
    "        errors: [N, 21] errors per joint per sample\n",
    "    \"\"\"\n",
    "    errors = np.linalg.norm(pred_joints - gt_joints, axis=-1)\n",
    "    return errors\n",
    "\n",
    "def procrustes_align(pred: np.ndarray, gt: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Align predicted pose to ground truth using Procrustes analysis\n",
    "    \n",
    "    Args:\n",
    "        pred: [21, 3] predicted joints\n",
    "        gt: [21, 3] ground truth joints\n",
    "    \n",
    "    Returns:\n",
    "        aligned: [21, 3] aligned predicted joints\n",
    "    \"\"\"\n",
    "    # Center the points\n",
    "    pred_centered = pred - pred.mean(axis=0)\n",
    "    gt_centered = gt - gt.mean(axis=0)\n",
    "    \n",
    "    # Compute optimal rotation\n",
    "    H = pred_centered.T @ gt_centered\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R_opt = Vt.T @ U.T\n",
    "    \n",
    "    # Handle reflection\n",
    "    if np.linalg.det(R_opt) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R_opt = Vt.T @ U.T\n",
    "    \n",
    "    # Apply transformation\n",
    "    aligned = pred_centered @ R_opt.T\n",
    "    aligned += gt.mean(axis=0)\n",
    "    \n",
    "    return aligned\n",
    "\n",
    "def compute_pa_mpjpe(pred_joints: np.ndarray, gt_joints: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute Procrustes-aligned MPJPE\n",
    "    \n",
    "    Args:\n",
    "        pred_joints: [N, 21, 3] predicted joints\n",
    "        gt_joints: [N, 21, 3] ground truth joints\n",
    "    \n",
    "    Returns:\n",
    "        pa_errors: [N] PA-MPJPE per sample\n",
    "    \"\"\"\n",
    "    N = pred_joints.shape[0]\n",
    "    pa_errors = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Align prediction to ground truth\n",
    "        aligned_pred = procrustes_align(pred_joints[i], gt_joints[i])\n",
    "        \n",
    "        # Compute error\n",
    "        error = np.mean(np.linalg.norm(aligned_pred - gt_joints[i], axis=-1))\n",
    "        pa_errors[i] = error\n",
    "    \n",
    "    return pa_errors\n",
    "\n",
    "def compute_pck(errors: np.ndarray, thresholds: List[float]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute Percentage of Correct Keypoints for different thresholds\n",
    "    \n",
    "    Args:\n",
    "        errors: [N] or [N, 21] error values\n",
    "        thresholds: List of threshold values in mm\n",
    "    \n",
    "    Returns:\n",
    "        pck_values: Dictionary with PCK values for each threshold\n",
    "    \"\"\"\n",
    "    # If per-joint errors, take mean\n",
    "    if errors.ndim > 1:\n",
    "        errors = errors.mean(axis=1)\n",
    "    \n",
    "    pck_values = {}\n",
    "    for threshold in thresholds:\n",
    "        correct = (errors < threshold).mean() * 100\n",
    "        pck_values[f'PCK@{threshold}mm'] = correct\n",
    "    \n",
    "    return pck_values\n",
    "\n",
    "def compute_auc(errors: np.ndarray, min_threshold: float = 0, \n",
    "                max_threshold: float = 50, num_steps: int = 100) -> Tuple[float, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute Area Under Curve for PCK metric\n",
    "    \n",
    "    Args:\n",
    "        errors: [N] error values\n",
    "        min_threshold: Minimum threshold for AUC\n",
    "        max_threshold: Maximum threshold for AUC\n",
    "        num_steps: Number of threshold steps\n",
    "    \n",
    "    Returns:\n",
    "        auc: Area under curve value\n",
    "        thresholds: Threshold values used\n",
    "        pck_values: PCK values at each threshold\n",
    "    \"\"\"\n",
    "    # If per-joint errors, take mean\n",
    "    if errors.ndim > 1:\n",
    "        errors = errors.mean(axis=1)\n",
    "    \n",
    "    thresholds = np.linspace(min_threshold, max_threshold, num_steps)\n",
    "    pck_values = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        pck = (errors < threshold).mean()\n",
    "        pck_values.append(pck)\n",
    "    \n",
    "    # Compute AUC using trapezoidal rule\n",
    "    auc = np.trapz(pck_values, thresholds) / (max_threshold - min_threshold)\n",
    "    \n",
    "    return auc, thresholds, np.array(pck_values)\n",
    "\n",
    "def compute_diversity(predictions: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute prediction diversity (std deviation) to detect mode collapse\n",
    "    \n",
    "    Args:\n",
    "        predictions: [N, 21, 3] all predictions\n",
    "    \n",
    "    Returns:\n",
    "        diversity_metrics: Dictionary with diversity measurements\n",
    "    \"\"\"\n",
    "    # Compute std deviation per joint\n",
    "    std_per_joint = np.std(predictions, axis=0)  # [21, 3]\n",
    "    mean_std = std_per_joint.mean()\n",
    "    \n",
    "    # Overall std (flattened)\n",
    "    overall_std = np.std(predictions.reshape(predictions.shape[0], -1), axis=0).mean()\n",
    "    \n",
    "    # Compute pairwise distances to check for duplicate predictions\n",
    "    n_samples = min(1000, len(predictions))  # Subsample for efficiency\n",
    "    indices = np.random.choice(len(predictions), n_samples, replace=False)\n",
    "    subset = predictions[indices].reshape(n_samples, -1)\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    dists = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            dists[i, j] = np.linalg.norm(subset[i] - subset[j])\n",
    "            dists[j, i] = dists[i, j]\n",
    "    \n",
    "    # Get minimum distance to another prediction (excluding self)\n",
    "    np.fill_diagonal(dists, np.inf)\n",
    "    min_dists = dists.min(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'mean_std_per_joint': mean_std,\n",
    "        'overall_std': overall_std,\n",
    "        'std_per_joint': std_per_joint,\n",
    "        'mean_min_distance': min_dists.mean(),\n",
    "        'min_min_distance': min_dists.min()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for demonstration\n",
    "# In practice, replace this with loading your actual predictions and ground truth\n",
    "\n",
    "def generate_sample_data(n_samples: int = 1000, noise_level: float = 5.0, \n",
    "                        mode_collapse: bool = False) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate sample prediction and ground truth data for testing\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples\n",
    "        noise_level: Noise level in mm for predictions\n",
    "        mode_collapse: If True, simulate mode collapse\n",
    "    \n",
    "    Returns:\n",
    "        pred_joints: [N, 21, 3] predicted joints\n",
    "        gt_joints: [N, 21, 3] ground truth joints\n",
    "    \"\"\"\n",
    "    # Generate ground truth hand poses\n",
    "    # Simple model: hand centered at origin with joints distributed\n",
    "    gt_joints = np.zeros((n_samples, 21, 3))\n",
    "    \n",
    "    # Wrist at origin\n",
    "    gt_joints[:, 0, :] = 0\n",
    "    \n",
    "    # Generate finger joints (simplified)\n",
    "    for sample in range(n_samples):\n",
    "        # Add some variation to hand poses\n",
    "        base_angles = np.random.randn(5) * 0.3  # Finger base angles\n",
    "        \n",
    "        for finger in range(5):\n",
    "            for joint in range(4):\n",
    "                joint_idx = 1 + finger * 4 + joint\n",
    "                if joint_idx < 21:\n",
    "                    # Simple forward kinematics\n",
    "                    length = 30 - joint * 5  # Joint lengths in mm\n",
    "                    angle = base_angles[finger] + joint * 0.2\n",
    "                    \n",
    "                    parent_idx = joint_idx - 1 if joint > 0 else 0\n",
    "                    gt_joints[sample, joint_idx, 0] = gt_joints[sample, parent_idx, 0] + length * np.cos(angle)\n",
    "                    gt_joints[sample, joint_idx, 1] = gt_joints[sample, parent_idx, 1] + length * np.sin(angle)\n",
    "                    gt_joints[sample, joint_idx, 2] = gt_joints[sample, parent_idx, 2] + np.random.randn() * 5\n",
    "    \n",
    "    # Generate predictions\n",
    "    if mode_collapse:\n",
    "        # Simulate mode collapse - all predictions are similar\n",
    "        mean_pose = gt_joints.mean(axis=0)\n",
    "        pred_joints = np.tile(mean_pose, (n_samples, 1, 1))\n",
    "        # Add tiny noise\n",
    "        pred_joints += np.random.randn(*pred_joints.shape) * 0.1\n",
    "    else:\n",
    "        # Normal predictions with noise\n",
    "        pred_joints = gt_joints + np.random.randn(*gt_joints.shape) * noise_level\n",
    "    \n",
    "    return pred_joints, gt_joints\n",
    "\n",
    "# Generate sample data\n",
    "print(\"Generating sample data...\")\n",
    "pred_joints, gt_joints = generate_sample_data(n_samples=1000, noise_level=10.0, mode_collapse=False)\n",
    "print(f\"Predictions shape: {pred_joints.shape}\")\n",
    "print(f\"Ground truth shape: {gt_joints.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all metrics\n",
    "print(\"Computing evaluation metrics...\")\n",
    "\n",
    "# 1. MPJPE\n",
    "mpjpe_errors = compute_mpjpe(pred_joints, gt_joints)  # [N, 21]\n",
    "mpjpe_mean = mpjpe_errors.mean()\n",
    "mpjpe_std = mpjpe_errors.mean(axis=1).std()  # Std across samples\n",
    "\n",
    "print(f\"\\nMPJPE: {mpjpe_mean:.2f} ± {mpjpe_std:.2f} mm\")\n",
    "\n",
    "# 2. PA-MPJPE\n",
    "pa_mpjpe_errors = compute_pa_mpjpe(pred_joints, gt_joints)\n",
    "pa_mpjpe_mean = pa_mpjpe_errors.mean()\n",
    "pa_mpjpe_std = pa_mpjpe_errors.std()\n",
    "\n",
    "print(f\"PA-MPJPE: {pa_mpjpe_mean:.2f} ± {pa_mpjpe_std:.2f} mm\")\n",
    "\n",
    "# 3. PCK at different thresholds\n",
    "thresholds = [5, 10, 15, 20, 30, 40, 50]\n",
    "pck_results = compute_pck(mpjpe_errors, thresholds)\n",
    "\n",
    "print(\"\\nPCK Results:\")\n",
    "for threshold_name, pck_value in pck_results.items():\n",
    "    print(f\"  {threshold_name}: {pck_value:.2f}%\")\n",
    "\n",
    "# 4. AUC\n",
    "auc, auc_thresholds, auc_pck_values = compute_auc(mpjpe_errors, 0, 50)\n",
    "print(f\"\\nAUC (0-50mm): {auc:.3f}\")\n",
    "\n",
    "# 5. Diversity\n",
    "diversity_metrics = compute_diversity(pred_joints)\n",
    "print(f\"\\nDiversity Metrics:\")\n",
    "print(f\"  Mean STD per joint: {diversity_metrics['mean_std_per_joint']:.4f} mm\")\n",
    "print(f\"  Overall STD: {diversity_metrics['overall_std']:.4f} mm\")\n",
    "print(f\"  Mean min distance between predictions: {diversity_metrics['mean_min_distance']:.4f} mm\")\n",
    "\n",
    "if diversity_metrics['mean_std_per_joint'] < 0.5:\n",
    "    print(\"  ⚠️ WARNING: Low diversity detected - possible mode collapse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint names for visualization\n",
    "joint_names = [\n",
    "    'Wrist', 'Thumb_1', 'Thumb_2', 'Thumb_3', 'Thumb_tip',\n",
    "    'Index_1', 'Index_2', 'Index_3', 'Index_tip',\n",
    "    'Middle_1', 'Middle_2', 'Middle_3', 'Middle_tip',\n",
    "    'Ring_1', 'Ring_2', 'Ring_3', 'Ring_tip',\n",
    "    'Pinky_1', 'Pinky_2', 'Pinky_3', 'Pinky_tip'\n",
    "]\n",
    "\n",
    "# Per-joint analysis\n",
    "per_joint_mpjpe = mpjpe_errors.mean(axis=0)  # Mean over samples\n",
    "print(\"\\nPer-Joint MPJPE Analysis:\")\n",
    "for joint_idx in range(21):\n",
    "    print(f\"  {joint_names[joint_idx]:12s}: {per_joint_mpjpe[joint_idx]:.2f} mm\")\n",
    "\n",
    "# Find worst performing joints\n",
    "worst_joints_idx = np.argsort(per_joint_mpjpe)[-5:]\n",
    "print(\"\\nWorst performing joints:\")\n",
    "for idx in reversed(worst_joints_idx):\n",
    "    print(f\"  {joint_names[idx]:12s}: {per_joint_mpjpe[idx]:.2f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: PCK Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(auc_thresholds, auc_pck_values * 100, 'b-', linewidth=2)\n",
    "plt.fill_between(auc_thresholds, 0, auc_pck_values * 100, alpha=0.3)\n",
    "plt.xlabel('Distance Threshold (mm)', fontsize=12)\n",
    "plt.ylabel('PCK (%)', fontsize=12)\n",
    "plt.title(f'PCK Curve (AUC = {auc:.3f})', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Add markers for specific thresholds\n",
    "for threshold in thresholds:\n",
    "    pck_val = pck_results[f'PCK@{threshold}mm']\n",
    "    plt.plot(threshold, pck_val, 'ro', markersize=8)\n",
    "    plt.text(threshold, pck_val + 2, f'{pck_val:.1f}%', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Per-Joint Error Analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar plot of per-joint errors\n",
    "colors = ['red' if i in [4, 8, 12, 16, 20] else 'blue' for i in range(21)]  # Fingertips in red\n",
    "bars = ax1.bar(range(21), per_joint_mpjpe, color=colors)\n",
    "ax1.set_xticks(range(21))\n",
    "ax1.set_xticklabels(joint_names, rotation=45, ha='right')\n",
    "ax1.set_ylabel('MPJPE (mm)', fontsize=12)\n",
    "ax1.set_title('Per-Joint MPJPE', fontsize=14)\n",
    "ax1.grid(True, axis='y', alpha=0.3)\n",
    "ax1.axhline(y=mpjpe_mean, color='green', linestyle='--', label=f'Mean: {mpjpe_mean:.2f}mm')\n",
    "ax1.legend()\n",
    "\n",
    "# Diversity per joint\n",
    "std_magnitude = np.linalg.norm(diversity_metrics['std_per_joint'], axis=1)\n",
    "bars2 = ax2.bar(range(21), std_magnitude, color='green')\n",
    "ax2.set_xticks(range(21))\n",
    "ax2.set_xticklabels(joint_names, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Prediction STD (mm)', fontsize=12)\n",
    "ax2.set_title('Per-Joint Prediction Diversity', fontsize=14)\n",
    "ax2.grid(True, axis='y', alpha=0.3)\n",
    "ax2.axhline(y=0.5, color='red', linestyle='--', label='Low diversity threshold')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Error Distribution Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# MPJPE distribution\n",
    "sample_mpjpe = mpjpe_errors.mean(axis=1)\n",
    "axes[0, 0].hist(sample_mpjpe, bins=50, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0, 0].axvline(mpjpe_mean, color='red', linestyle='--', label=f'Mean: {mpjpe_mean:.2f}')\n",
    "axes[0, 0].set_xlabel('MPJPE (mm)')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].set_title('MPJPE Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# PA-MPJPE distribution\n",
    "axes[0, 1].hist(pa_mpjpe_errors, bins=50, density=True, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0, 1].axvline(pa_mpjpe_mean, color='red', linestyle='--', label=f'Mean: {pa_mpjpe_mean:.2f}')\n",
    "axes[0, 1].set_xlabel('PA-MPJPE (mm)')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('PA-MPJPE Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# MPJPE vs PA-MPJPE scatter\n",
    "axes[1, 0].scatter(sample_mpjpe, pa_mpjpe_errors, alpha=0.5, s=10)\n",
    "max_val = max(sample_mpjpe.max(), pa_mpjpe_errors.max())\n",
    "axes[1, 0].plot([0, max_val], [0, max_val], 'r--', label='y=x')\n",
    "axes[1, 0].set_xlabel('MPJPE (mm)')\n",
    "axes[1, 0].set_ylabel('PA-MPJPE (mm)')\n",
    "axes[1, 0].set_title('MPJPE vs PA-MPJPE')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative error distribution\n",
    "sorted_mpjpe = np.sort(sample_mpjpe)\n",
    "cumulative = np.arange(1, len(sorted_mpjpe) + 1) / len(sorted_mpjpe) * 100\n",
    "axes[1, 1].plot(sorted_mpjpe, cumulative, 'b-', linewidth=2)\n",
    "axes[1, 1].set_xlabel('MPJPE (mm)')\n",
    "axes[1, 1].set_ylabel('Cumulative Percentage (%)')\n",
    "axes[1, 1].set_title('Cumulative Error Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add percentile markers\n",
    "percentiles = [50, 75, 90, 95]\n",
    "for p in percentiles:\n",
    "    val = np.percentile(sample_mpjpe, p)\n",
    "    axes[1, 1].axvline(val, color='red', linestyle=':', alpha=0.5)\n",
    "    axes[1, 1].text(val + 0.5, p - 5, f'{p}%: {val:.1f}mm', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mode collapse scenario\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Mode Collapse Scenario\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate data with mode collapse\n",
    "pred_collapse, gt_collapse = generate_sample_data(n_samples=1000, noise_level=10.0, mode_collapse=True)\n",
    "\n",
    "# Compute metrics\n",
    "mpjpe_collapse = compute_mpjpe(pred_collapse, gt_collapse).mean()\n",
    "diversity_collapse = compute_diversity(pred_collapse)\n",
    "\n",
    "print(f\"\\nMode Collapse Results:\")\n",
    "print(f\"  MPJPE: {mpjpe_collapse:.2f} mm\")\n",
    "print(f\"  Mean STD per joint: {diversity_collapse['mean_std_per_joint']:.4f} mm\")\n",
    "print(f\"  Min distance between predictions: {diversity_collapse['min_min_distance']:.4f} mm\")\n",
    "\n",
    "if diversity_collapse['mean_std_per_joint'] < 0.5:\n",
    "    print(\"  ❌ Mode collapse confirmed - all predictions are nearly identical!\")\n",
    "\n",
    "# Compare normal vs collapsed\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"  Normal diversity: {diversity_metrics['mean_std_per_joint']:.4f} mm\")\n",
    "print(f\"  Collapsed diversity: {diversity_collapse['mean_std_per_joint']:.4f} mm\")\n",
    "print(f\"  Ratio: {diversity_metrics['mean_std_per_joint'] / diversity_collapse['mean_std_per_joint']:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset size: {len(pred_joints)} samples\")\n",
    "print(f\"\\nKey Metrics:\")\n",
    "print(f\"  - MPJPE: {mpjpe_mean:.2f} ± {mpjpe_std:.2f} mm\")\n",
    "print(f\"  - PA-MPJPE: {pa_mpjpe_mean:.2f} ± {pa_mpjpe_std:.2f} mm\")\n",
    "print(f\"  - PCK@20mm: {pck_results['PCK@20mm']:.2f}%\")\n",
    "print(f\"  - AUC (0-50mm): {auc:.3f}\")\n",
    "print(f\"  - Diversity: {diversity_metrics['mean_std_per_joint']:.4f} mm\")\n",
    "\n",
    "print(\"\\nPerformance Assessment:\")\n",
    "if mpjpe_mean < 20:\n",
    "    print(\"  ✅ Excellent performance (MPJPE < 20mm)\")\n",
    "elif mpjpe_mean < 50:\n",
    "    print(\"  ✓ Good performance (MPJPE < 50mm)\")\n",
    "elif mpjpe_mean < 100:\n",
    "    print(\"  ⚠️ Moderate performance (MPJPE < 100mm)\")\n",
    "else:\n",
    "    print(\"  ❌ Poor performance (MPJPE > 100mm)\")\n",
    "\n",
    "if diversity_metrics['mean_std_per_joint'] < 0.5:\n",
    "    print(\"  ❌ Mode collapse detected (low diversity)\")\n",
    "else:\n",
    "    print(\"  ✅ Good prediction diversity\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and evaluate your actual model predictions\n",
    "def evaluate_predictions(pred_file: str, gt_file: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load predictions and ground truth from files and compute all metrics\n",
    "    \n",
    "    Args:\n",
    "        pred_file: Path to predictions file (numpy .npy or .npz)\n",
    "        gt_file: Path to ground truth file\n",
    "    \n",
    "    Returns:\n",
    "        results: Dictionary with all computed metrics\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    predictions = np.load(pred_file)\n",
    "    ground_truth = np.load(gt_file)\n",
    "    \n",
    "    # Ensure correct shape [N, 21, 3]\n",
    "    if predictions.ndim == 2:\n",
    "        predictions = predictions.reshape(-1, 21, 3)\n",
    "    if ground_truth.ndim == 2:\n",
    "        ground_truth = ground_truth.reshape(-1, 21, 3)\n",
    "    \n",
    "    # Compute all metrics\n",
    "    mpjpe_errors = compute_mpjpe(predictions, ground_truth)\n",
    "    pa_mpjpe_errors = compute_pa_mpjpe(predictions, ground_truth)\n",
    "    pck_results = compute_pck(mpjpe_errors, [5, 10, 15, 20, 30, 40, 50])\n",
    "    auc, _, _ = compute_auc(mpjpe_errors, 0, 50)\n",
    "    diversity = compute_diversity(predictions)\n",
    "    \n",
    "    results = {\n",
    "        'mpjpe': mpjpe_errors.mean(),\n",
    "        'mpjpe_std': mpjpe_errors.mean(axis=1).std(),\n",
    "        'pa_mpjpe': pa_mpjpe_errors.mean(),\n",
    "        'pa_mpjpe_std': pa_mpjpe_errors.std(),\n",
    "        'pck': pck_results,\n",
    "        'auc': auc,\n",
    "        'diversity': diversity,\n",
    "        'per_joint_mpjpe': mpjpe_errors.mean(axis=0)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment and modify paths when you have actual data):\n",
    "# results = evaluate_predictions('path/to/predictions.npy', 'path/to/ground_truth.npy')\n",
    "# print(f\"MPJPE: {results['mpjpe']:.2f} mm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}