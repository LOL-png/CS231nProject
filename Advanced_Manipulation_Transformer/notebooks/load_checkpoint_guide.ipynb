{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Checkpoint Files - Complete Guide\n",
    "\n",
    "This notebook shows all the different ways to load saved checkpoint files in the Advanced Manipulation Transformer project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Load Checkpoint for Evaluation Only\n",
    "\n",
    "Use this when you just want to evaluate a trained model without continuing training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath('./'))))\n",
    "\n",
    "from Advanced_Manipulation_Transformer.models.unified_model import UnifiedManipulationTransformer\n",
    "\n",
    "# Method 1: Load checkpoint for evaluation\n",
    "def load_model_for_evaluation(checkpoint_path, device='cuda'):\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Extract config from checkpoint\n",
    "    config = checkpoint.get('config', {})\n",
    "    \n",
    "    # Create model\n",
    "    model = UnifiedManipulationTransformer(config.get('model', {}))\n",
    "    \n",
    "    # Load model weights\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    elif 'state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        # Assume checkpoint is just the state dict\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # Load EMA weights if available (usually better for evaluation)\n",
    "    if 'ema_state_dict' in checkpoint:\n",
    "        print(\"Loading EMA weights for evaluation\")\n",
    "        model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Print checkpoint info\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"Loaded checkpoint from epoch: {checkpoint['epoch']}\")\n",
    "    if 'metrics' in checkpoint:\n",
    "        print(f\"Checkpoint metrics: {checkpoint['metrics']}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "# Example usage\n",
    "checkpoint_path = 'checkpoints/best.pth'  # Update with your path\n",
    "# model, checkpoint_info = load_model_for_evaluation(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Resume Training from Checkpoint\n",
    "\n",
    "Use this when you want to continue training from where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Advanced_Manipulation_Transformer.training.trainer import ManipulationTrainer\n",
    "\n",
    "def resume_training_from_checkpoint(checkpoint_path, config):\n",
    "    \"\"\"\n",
    "    Resume training from a checkpoint, including optimizer and scheduler states\n",
    "    \"\"\"\n",
    "    # Create model\n",
    "    model = UnifiedManipulationTransformer(config['model'])\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = ManipulationTrainer(\n",
    "        model=model,\n",
    "        config=config['training'],\n",
    "        device='cuda'\n",
    "    )\n",
    "    \n",
    "    # Load checkpoint (this loads model, optimizer, scheduler, etc.)\n",
    "    trainer.load_checkpoint(checkpoint_path)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "# Example usage\n",
    "# config = {...}  # Your training config\n",
    "# trainer = resume_training_from_checkpoint('checkpoints/latest.pth', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Command Line - Resume Training\n",
    "\n",
    "The easiest way to resume training is using the command line with Hydra config overrides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line examples for resuming training\n",
    "\n",
    "print(\"\"\"# Resume from latest checkpoint:\n",
    "python train_advanced.py checkpoint.resume_from=outputs/experiment_name/checkpoints/latest.pth\n",
    "\n",
    "# Resume from best checkpoint:\n",
    "python train_advanced.py checkpoint.resume_from=outputs/experiment_name/checkpoints/best.pth\n",
    "\n",
    "# Resume from specific epoch:\n",
    "python train_advanced.py checkpoint.resume_from=outputs/experiment_name/checkpoints/epoch_20.pth\n",
    "\n",
    "# Resume with different settings:\n",
    "python train_advanced.py \\\\\n",
    "    checkpoint.resume_from=checkpoints/best.pth \\\\\n",
    "    training.learning_rate=5e-4 \\\\\n",
    "    training.batch_size=64\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Load Specific Components\n",
    "\n",
    "Sometimes you only want to load certain parts of the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_partial_checkpoint(checkpoint_path, model=None, load_components=['model']):\n",
    "    \"\"\"\n",
    "    Load only specific components from checkpoint\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint file\n",
    "        model: Model instance (create new if None)\n",
    "        load_components: List of components to load:\n",
    "            - 'model': Model weights\n",
    "            - 'ema': EMA model weights\n",
    "            - 'optimizer': Optimizer state\n",
    "            - 'scheduler': Scheduler state\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cuda')\n",
    "    \n",
    "    loaded = {}\n",
    "    \n",
    "    # Load model weights\n",
    "    if 'model' in load_components:\n",
    "        if model is None:\n",
    "            config = checkpoint.get('config', {})\n",
    "            model = UnifiedManipulationTransformer(config.get('model', {}))\n",
    "        \n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            loaded['model'] = model\n",
    "    \n",
    "    # Load EMA weights\n",
    "    if 'ema' in load_components and 'ema_state_dict' in checkpoint:\n",
    "        loaded['ema_weights'] = checkpoint['ema_state_dict']\n",
    "    \n",
    "    # Load optimizer state\n",
    "    if 'optimizer' in load_components and 'optimizer_state_dict' in checkpoint:\n",
    "        loaded['optimizer_state'] = checkpoint['optimizer_state_dict']\n",
    "    \n",
    "    # Load scheduler state\n",
    "    if 'scheduler' in load_components and 'scheduler_state_dict' in checkpoint:\n",
    "        loaded['scheduler_state'] = checkpoint['scheduler_state_dict']\n",
    "    \n",
    "    # Additional info\n",
    "    loaded['epoch'] = checkpoint.get('epoch', 0)\n",
    "    loaded['global_step'] = checkpoint.get('global_step', 0)\n",
    "    loaded['metrics'] = checkpoint.get('metrics', {})\n",
    "    \n",
    "    return loaded\n",
    "\n",
    "# Example: Load only model weights\n",
    "# components = load_partial_checkpoint('checkpoints/best.pth', load_components=['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 5: Load for Fine-tuning\n",
    "\n",
    "When you want to fine-tune a pre-trained model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_for_finetuning(checkpoint_path, freeze_backbone=True, freeze_layers=12):\n",
    "    \"\"\"\n",
    "    Load model for fine-tuning with optional freezing of backbone layers\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model, checkpoint = load_model_for_evaluation(checkpoint_path)\n",
    "    \n",
    "    # Set to training mode\n",
    "    model.train()\n",
    "    \n",
    "    if freeze_backbone:\n",
    "        # Freeze DINOv2 backbone layers\n",
    "        frozen_params = 0\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'image_encoder.dinov2' in name:\n",
    "                # Extract layer number if possible\n",
    "                layer_num = None\n",
    "                if 'blocks.' in name:\n",
    "                    try:\n",
    "                        layer_num = int(name.split('blocks.')[1].split('.')[0])\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # Freeze if it's in the first N layers\n",
    "                if layer_num is None or layer_num < freeze_layers:\n",
    "                    param.requires_grad = False\n",
    "                    frozen_params += param.numel()\n",
    "        \n",
    "        print(f\"Froze {frozen_params:,} parameters in backbone\")\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: Load and freeze first 12 layers\n",
    "# model = load_for_finetuning('checkpoints/best.pth', freeze_backbone=True, freeze_layers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 6: Load and Convert Checkpoints\n",
    "\n",
    "Sometimes you need to convert between different checkpoint formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_checkpoint_format(input_path, output_path, target_format='standard'):\n",
    "    \"\"\"\n",
    "    Convert between different checkpoint formats\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input checkpoint\n",
    "        output_path: Path to save converted checkpoint\n",
    "        target_format: 'standard', 'minimal', or 'inference'\n",
    "    \"\"\"\n",
    "    # Load original checkpoint\n",
    "    checkpoint = torch.load(input_path, map_location='cpu')\n",
    "    \n",
    "    if target_format == 'minimal':\n",
    "        # Save only model weights\n",
    "        minimal_checkpoint = {\n",
    "            'model_state_dict': checkpoint.get('model_state_dict', checkpoint),\n",
    "            'config': checkpoint.get('config', {})\n",
    "        }\n",
    "        torch.save(minimal_checkpoint, output_path)\n",
    "        \n",
    "    elif target_format == 'inference':\n",
    "        # Save model with EMA weights for inference\n",
    "        inference_checkpoint = {}\n",
    "        \n",
    "        # Use EMA weights if available, otherwise regular weights\n",
    "        if 'ema_state_dict' in checkpoint:\n",
    "            inference_checkpoint['model_state_dict'] = checkpoint['ema_state_dict']\n",
    "        else:\n",
    "            inference_checkpoint['model_state_dict'] = checkpoint.get('model_state_dict', checkpoint)\n",
    "        \n",
    "        inference_checkpoint['config'] = checkpoint.get('config', {})\n",
    "        torch.save(inference_checkpoint, output_path)\n",
    "        \n",
    "    elif target_format == 'standard':\n",
    "        # Save full checkpoint\n",
    "        torch.save(checkpoint, output_path)\n",
    "    \n",
    "    print(f\"Converted checkpoint saved to: {output_path}\")\n",
    "    print(f\"Original size: {os.path.getsize(input_path) / 1e6:.1f} MB\")\n",
    "    print(f\"New size: {os.path.getsize(output_path) / 1e6:.1f} MB\")\n",
    "\n",
    "# Example: Convert to minimal checkpoint for sharing\n",
    "# convert_checkpoint_format('checkpoints/best.pth', 'checkpoints/best_minimal.pth', 'minimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 7: Inspect Checkpoint Contents\n",
    "\n",
    "Before loading, you might want to inspect what's in the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_checkpoint(checkpoint_path):\n",
    "    \"\"\"\n",
    "    Inspect contents of a checkpoint file without loading the full model\n",
    "    \"\"\"\n",
    "    # Load checkpoint structure only\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    \n",
    "    print(f\"Checkpoint: {checkpoint_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nCheckpoint keys: {list(checkpoint.keys())}\")\n",
    "    \n",
    "    # Training info\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"\\nEpoch: {checkpoint['epoch']}\")\n",
    "    if 'global_step' in checkpoint:\n",
    "        print(f\"Global step: {checkpoint['global_step']}\")\n",
    "    \n",
    "    # Metrics\n",
    "    if 'metrics' in checkpoint:\n",
    "        print(\"\\nMetrics:\")\n",
    "        for k, v in checkpoint['metrics'].items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    \n",
    "    # Model info\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        print(f\"\\nModel parameters: {len(state_dict)} tensors\")\n",
    "        total_params = sum(p.numel() for p in state_dict.values())\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        \n",
    "        # Show first few layers\n",
    "        print(\"\\nFirst 5 layers:\")\n",
    "        for i, (name, tensor) in enumerate(state_dict.items()):\n",
    "            if i >= 5:\n",
    "                break\n",
    "            print(f\"  {name}: {tensor.shape}\")\n",
    "    \n",
    "    # Config info\n",
    "    if 'config' in checkpoint:\n",
    "        print(\"\\nConfig summary:\")\n",
    "        config = checkpoint['config']\n",
    "        if isinstance(config, dict):\n",
    "            for key in ['model', 'training', 'data']:\n",
    "                if key in config:\n",
    "                    print(f\"  {key}: {list(config[key].keys())[:5]}...\")\n",
    "\n",
    "# Example usage\n",
    "# inspect_checkpoint('checkpoints/best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Checkpoint Locations\n",
    "\n",
    "The Advanced Manipulation Transformer saves checkpoints in these locations by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default checkpoint locations\n",
    "print(\"\"\"Common checkpoint locations:\n",
    "\n",
    "1. Latest checkpoint (auto-saved):\n",
    "   outputs/<experiment_name>/checkpoints/latest.pth\n",
    "\n",
    "2. Best checkpoint (lowest validation loss):\n",
    "   outputs/<experiment_name>/checkpoints/best.pth\n",
    "\n",
    "3. Periodic checkpoints:\n",
    "   outputs/<experiment_name>/checkpoints/epoch_10.pth\n",
    "   outputs/<experiment_name>/checkpoints/epoch_20.pth\n",
    "   ...\n",
    "\n",
    "4. Custom checkpoints directory:\n",
    "   Set with: checkpoint.checkpoint_dir=path/to/dir\n",
    "\n",
    "5. Pre-trained models (if provided):\n",
    "   pretrained/dinov2_hand_pose.pth\n",
    "   pretrained/amt_dexycb.pth\n",
    "\"\"\")\n",
    "\n",
    "# List available checkpoints\n",
    "import glob\n",
    "\n",
    "def list_available_checkpoints(checkpoint_dir='outputs'):\n",
    "    \"\"\"List all available checkpoint files\"\"\"\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/**/checkpoints/*.pth\", recursive=True)\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(f\"Found {len(checkpoints)} checkpoints:\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            size_mb = os.path.getsize(ckpt) / 1e6\n",
    "            print(f\"  {ckpt} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"No checkpoints found in {checkpoint_dir}\")\n",
    "\n",
    "# Example: List all checkpoints\n",
    "# list_available_checkpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example: Load and Evaluate\n",
    "\n",
    "Here's a complete example that loads a checkpoint and runs evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate(checkpoint_path, test_loader=None):\n",
    "    \"\"\"\n",
    "    Complete example: Load checkpoint and run evaluation\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    model, checkpoint_info = load_model_for_evaluation(checkpoint_path)\n",
    "    \n",
    "    # Create dummy test data if no loader provided\n",
    "    if test_loader is None:\n",
    "        print(\"\\nCreating dummy test data...\")\n",
    "        batch_size = 4\n",
    "        dummy_batch = {\n",
    "            'color': torch.randn(batch_size, 3, 224, 224).cuda(),\n",
    "            'hand_joints_3d': torch.randn(batch_size, 21, 3).cuda(),\n",
    "            'object_pose': torch.randn(batch_size, 3, 4).cuda(),\n",
    "            'camera_intrinsics': torch.eye(3).unsqueeze(0).repeat(batch_size, 1, 1).cuda()\n",
    "        }\n",
    "        test_loader = [dummy_batch]  # Single batch for testing\n",
    "    \n",
    "    # Run evaluation\n",
    "    print(\"\\nRunning evaluation...\")\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch)\n",
    "            \n",
    "            # Extract predictions\n",
    "            predictions = {\n",
    "                'hand_joints': outputs['hand_joints'].cpu().numpy(),\n",
    "                'object_positions': outputs['object_positions'].cpu().numpy(),\n",
    "                'object_rotations': outputs['object_rotations'].cpu().numpy(),\n",
    "            }\n",
    "            \n",
    "            if 'contact_points' in outputs:\n",
    "                predictions['contact_points'] = outputs['contact_points'].cpu().numpy()\n",
    "            \n",
    "            all_predictions.append(predictions)\n",
    "            break  # Just one batch for demo\n",
    "    \n",
    "    print(\"\\nPrediction shapes:\")\n",
    "    for key, value in predictions.items():\n",
    "        print(f\"  {key}: {value.shape}\")\n",
    "    \n",
    "    return model, all_predictions\n",
    "\n",
    "# Example usage\n",
    "# model, predictions = load_and_evaluate('checkpoints/best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Common Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_load_checkpoint(checkpoint_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Safely load checkpoint with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try loading normally\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        print(\"✓ Checkpoint loaded successfully\")\n",
    "        return checkpoint\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(\"✗ CUDA OOM - trying CPU load\")\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            print(\"✓ Loaded on CPU\")\n",
    "            return checkpoint\n",
    "        \n",
    "        elif \"Missing key(s)\" in str(e):\n",
    "            print(\"✗ Model architecture mismatch\")\n",
    "            print(\"  Try loading with strict=False:\")\n",
    "            print(\"  model.load_state_dict(checkpoint['model_state_dict'], strict=False)\")\n",
    "            raise e\n",
    "        \n",
    "        else:\n",
    "            print(f\"✗ Error loading checkpoint: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ Checkpoint not found: {checkpoint_path}\")\n",
    "        print(\"  Available checkpoints:\")\n",
    "        list_available_checkpoints()\n",
    "        raise\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error: {type(e).__name__}: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example with error handling\n",
    "# checkpoint = safe_load_checkpoint('checkpoints/best.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}