{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Video-to-Manipulation Transformer: GPU-Only Stage 1 Training\n\nThis notebook implements the fastest GPU-only training approach for maximum performance on H200.\n\n**Key Features:**\n- Entire dataset cached in GPU memory (zero CPU-GPU transfers)\n- Large batch sizes (1024+)\n- BFloat16 mixed precision\n- Compiled models for better performance\n- No DataLoader overhead\n\n**Requirements:**\n- H200 GPU with 140GB memory\n- PyTorch 2.0+ for torch.compile\n- CUDA 12.0+",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H200\n",
      "Memory: 150.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "# CRITICAL: Set multiprocessing start method for CUDA\n",
    "import multiprocessing\n",
    "try:\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set\n",
    "\n",
    "# Set environment\n",
    "os.environ['DEX_YCB_DIR'] = '/home/n231/231nProjectV2/dex-ycb-toolkit/data'\n",
    "\n",
    "# CUDA optimizations for H200\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('.')\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import our modules\n",
    "from models.encoders.hand_encoder import HandPoseEncoder\n",
    "from models.encoders.object_encoder import ObjectPoseEncoder\n",
    "from models.encoders.contact_encoder import ContactDetectionEncoder\n",
    "from data.dexycb_dataset import DexYCBDataset\n",
    "from data.gpu_preprocessing import GPUVideoPreprocessor, FastDataCollator\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H200 Configuration loaded\n",
      "Effective batch size: 512\n"
     ]
    }
   ],
   "source": [
    "# H200 Optimized Configuration\n",
    "config = {\n",
    "    # Data settings - maximize throughput\n",
    "    'batch_size': 256,  # Large batch for H200\n",
    "    'num_workers': 0,   # CRITICAL: Set to 0 to avoid CUDA fork error\n",
    "    'pin_memory': True,\n",
    "    'persistent_workers': False,  # Not needed with 0 workers\n",
    "    \n",
    "    # Model settings - scale up\n",
    "    'patch_size': 16,\n",
    "    'image_size': [224, 224],\n",
    "    'hand_hidden_dim': 1024,  # 2x larger\n",
    "    'object_hidden_dim': 1024,\n",
    "    'contact_hidden_dim': 512,\n",
    "    'hand_layers': 12,  # 2x deeper\n",
    "    'object_layers': 12,\n",
    "    'contact_layers': 8,\n",
    "    \n",
    "    # Training settings\n",
    "    'learning_rate': 5e-4,\n",
    "    'num_epochs': 5,\n",
    "    'grad_clip': 1.0,\n",
    "    'warmup_steps': 100,\n",
    "    'accumulation_steps': 2,  # Effective batch = 512\n",
    "    \n",
    "    # Mixed precision\n",
    "    'use_amp': True,\n",
    "    'amp_dtype': torch.bfloat16,\n",
    "    \n",
    "    # Logging\n",
    "    'log_interval': 10,\n",
    "    'val_interval': 50\n",
    "}\n",
    "\n",
    "print(\"H200 Configuration loaded\")\n",
    "print(f\"Effective batch size: {config['batch_size'] * config['accumulation_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Training samples: 465,504\n",
      "Validation samples: 23,200\n",
      "Train batches per epoch: 1818\n",
      "✓ Data loaders created with GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "\n",
    "train_dataset = DexYCBDataset(split='s0_train', max_objects=10)\n",
    "val_dataset = DexYCBDataset(split='s0_val', max_objects=10)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(val_dataset):,}\")\n",
    "\n",
    "# Create GPU-accelerated data loaders\n",
    "# Use FastDataCollator to move data directly to GPU\n",
    "collate_fn = FastDataCollator(device='cuda')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],  # 0 to avoid CUDA fork\n",
    "    pin_memory=config['pin_memory'],\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Always 0 for validation\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Train batches per epoch: {len(train_loader)}\")\n",
    "print(\"✓ Data loaders created with GPU acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating scaled-up models...\n",
      "Compiling models...\n",
      "\n",
      "Model parameters:\n",
      "  Hand encoder: 153.6M\n",
      "  Object encoder: 153.2M\n",
      "  Contact encoder: 27.6M\n",
      "  Total: 334.4M\n",
      "\n",
      "GPU Memory: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "# Create scaled-up models for H200\n",
    "print(\"Creating scaled-up models...\")\n",
    "\n",
    "patch_dim = 3 * config['patch_size'] * config['patch_size']\n",
    "\n",
    "# Large hand encoder\n",
    "hand_encoder = HandPoseEncoder(\n",
    "    input_dim=patch_dim,\n",
    "    hidden_dim=config['hand_hidden_dim'],\n",
    "    num_layers=config['hand_layers'],\n",
    "    num_heads=16,\n",
    "    mlp_dim=4096,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Large object encoder\n",
    "object_encoder = ObjectPoseEncoder(\n",
    "    input_dim=patch_dim,\n",
    "    hidden_dim=config['object_hidden_dim'],\n",
    "    num_layers=config['object_layers'],\n",
    "    num_heads=16,\n",
    "    mlp_dim=4096,\n",
    "    dropout=0.1,\n",
    "    max_objects=10\n",
    ").to(device)\n",
    "\n",
    "# Large contact encoder\n",
    "contact_encoder = ContactDetectionEncoder(\n",
    "    input_dim=patch_dim,\n",
    "    hidden_dim=config['contact_hidden_dim'],\n",
    "    num_layers=config['contact_layers'],\n",
    "    num_heads=16,\n",
    "    mlp_dim=2048,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Compile models for better performance\n",
    "if hasattr(torch, 'compile'):\n",
    "    print(\"Compiling models...\")\n",
    "    hand_encoder = torch.compile(hand_encoder, mode='default')\n",
    "    object_encoder = torch.compile(object_encoder, mode='default')\n",
    "    contact_encoder = torch.compile(contact_encoder, mode='default')\n",
    "\n",
    "# Model info\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = (count_parameters(hand_encoder) + \n",
    "                count_parameters(object_encoder) + \n",
    "                count_parameters(contact_encoder))\n",
    "\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Hand encoder: {count_parameters(hand_encoder)/1e6:.1f}M\")\n",
    "print(f\"  Object encoder: {count_parameters(object_encoder)/1e6:.1f}M\")\n",
    "print(f\"  Contact encoder: {count_parameters(contact_encoder)/1e6:.1f}M\")\n",
    "print(f\"  Total: {total_params/1e6:.1f}M\")\n",
    "\n",
    "print(f\"\\nGPU Memory: {torch.cuda.memory_allocated()/1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Optimizers and mixed precision configured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112421/1973905690.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_hand = GradScaler(enabled=config['use_amp'])\n",
      "/tmp/ipykernel_112421/1973905690.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_object = GradScaler(enabled=config['use_amp'])\n",
      "/tmp/ipykernel_112421/1973905690.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_contact = GradScaler(enabled=config['use_amp'])\n"
     ]
    }
   ],
   "source": [
    "# Create GPU preprocessor\n",
    "gpu_preprocessor = GPUVideoPreprocessor(\n",
    "    image_size=tuple(config['image_size']),\n",
    "    patch_size=config['patch_size'],\n",
    "    normalize=True,\n",
    "    device='cuda'\n",
    ").to(device)\n",
    "\n",
    "# Setup optimizers and schedulers\n",
    "optimizer_hand = optim.AdamW(hand_encoder.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "optimizer_object = optim.AdamW(object_encoder.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "optimizer_contact = optim.AdamW(contact_encoder.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "# Mixed precision scalers\n",
    "scaler_hand = GradScaler(enabled=config['use_amp'])\n",
    "scaler_object = GradScaler(enabled=config['use_amp'])\n",
    "scaler_contact = GradScaler(enabled=config['use_amp'])\n",
    "\n",
    "# Loss function\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "print(\"✓ Optimizers and mixed precision configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H200 Optimized Training Function\n",
    "def train_epoch(epoch):\n",
    "    \"\"\"Optimized training for H200 with mixed precision\"\"\"\n",
    "    hand_encoder.train()\n",
    "    object_encoder.train()\n",
    "    contact_encoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    data_time = 0\n",
    "    compute_time = 0\n",
    "    batch_start = time.time()\n",
    "    \n",
    "    # Zero gradients at start\n",
    "    optimizer_hand.zero_grad(set_to_none=True)\n",
    "    optimizer_object.zero_grad(set_to_none=True)\n",
    "    optimizer_contact.zero_grad(set_to_none=True)\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Data loading time\n",
    "        data_time += time.time() - batch_start\n",
    "        compute_start = time.time()\n",
    "        \n",
    "        # All data is already on GPU thanks to FastDataCollator\n",
    "        # Process images through GPU preprocessor\n",
    "        with torch.no_grad():\n",
    "            patches = gpu_preprocessor(batch['color'])\n",
    "        \n",
    "        # Prepare ground truth\n",
    "        hand_gt = batch['hand_joints_3d']\n",
    "        if hand_gt.dim() == 4 and hand_gt.shape[1] == 1:\n",
    "            hand_gt = hand_gt.squeeze(1)\n",
    "        \n",
    "        valid_hands = ~torch.all(hand_gt.view(hand_gt.shape[0], -1) == -1, dim=1)\n",
    "        \n",
    "        # === MIXED PRECISION FORWARD PASSES ===\n",
    "        \n",
    "        # Hand encoder\n",
    "        with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "            hand_output = hand_encoder(patches)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                hand_loss = mse_loss(\n",
    "                    hand_output['joints_3d'][valid_hands],\n",
    "                    hand_gt[valid_hands]\n",
    "                ) / config['accumulation_steps']\n",
    "            else:\n",
    "                hand_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "        \n",
    "        # Backward for hand\n",
    "        scaler_hand.scale(hand_loss).backward()\n",
    "        \n",
    "        # Object encoder\n",
    "        with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "            object_output = object_encoder(patches, object_ids=batch.get('ycb_ids', None))\n",
    "            \n",
    "            # Object loss\n",
    "            object_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "            if batch['object_poses'].shape[1] > 0:\n",
    "                valid_objects = ~torch.all(batch['object_poses'] == 0, dim=(2, 3))\n",
    "                if valid_objects.any():\n",
    "                    object_positions_gt = batch['object_poses'][:, :, :3, 3]\n",
    "                    num_pred_objects = min(object_output['positions'].shape[1], batch['object_poses'].shape[1])\n",
    "                    valid_mask = valid_objects[:, :num_pred_objects]\n",
    "                    \n",
    "                    if valid_mask.any():\n",
    "                        pred_positions = object_output['positions'][:, :num_pred_objects]\n",
    "                        gt_positions = object_positions_gt[:, :num_pred_objects]\n",
    "                        pred_flat = pred_positions[valid_mask]\n",
    "                        gt_flat = gt_positions[valid_mask]\n",
    "                        object_loss = mse_loss(pred_flat, gt_flat) / config['accumulation_steps']\n",
    "        \n",
    "        # Backward for object\n",
    "        scaler_object.scale(object_loss).backward()\n",
    "        \n",
    "        # Contact encoder (no ground truth)\n",
    "        with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "            contact_output = contact_encoder(\n",
    "                hand_output['features'].detach(),\n",
    "                object_output['features'].detach()\n",
    "            )\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (batch_idx + 1) % config['accumulation_steps'] == 0:\n",
    "            # Unscale and clip gradients\n",
    "            scaler_hand.unscale_(optimizer_hand)\n",
    "            scaler_object.unscale_(optimizer_object)\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(hand_encoder.parameters(), config['grad_clip'])\n",
    "            torch.nn.utils.clip_grad_norm_(object_encoder.parameters(), config['grad_clip'])\n",
    "            \n",
    "            # Optimizer steps\n",
    "            scaler_hand.step(optimizer_hand)\n",
    "            scaler_object.step(optimizer_object)\n",
    "            scaler_contact.step(optimizer_contact)\n",
    "            \n",
    "            # Update scalers\n",
    "            scaler_hand.update()\n",
    "            scaler_object.update()\n",
    "            scaler_contact.update()\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer_hand.zero_grad(set_to_none=True)\n",
    "            optimizer_object.zero_grad(set_to_none=True)\n",
    "            optimizer_contact.zero_grad(set_to_none=True)\n",
    "        \n",
    "        compute_time += time.time() - compute_start\n",
    "        \n",
    "        # Update metrics\n",
    "        total_loss += hand_loss.item() * config['accumulation_steps'] + object_loss.item() * config['accumulation_steps']\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "        samples_per_sec = (batch_idx + 1) * config['batch_size'] / (time.time() - progress_bar.start_t)\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{(hand_loss.item() + object_loss.item()) * config[\"accumulation_steps\"]:.4f}',\n",
    "            'gpu_gb': f'{gpu_mem:.1f}',\n",
    "            'speed': f'{samples_per_sec:.0f}',\n",
    "        })\n",
    "        \n",
    "        # Log periodically\n",
    "        if (batch_idx + 1) % config['log_interval'] == 0:\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] \"\n",
    "                  f\"GPU: {gpu_mem:.1f}GB | \"\n",
    "                  f\"Speed: {samples_per_sec:.0f} samples/s\")\n",
    "        \n",
    "        batch_start = time.time()\n",
    "    \n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "def validate():\n",
    "    \"\"\"Fast validation\"\"\"\n",
    "    hand_encoder.eval()\n",
    "    object_encoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_mpjpe = 0\n",
    "    num_batches = 0\n",
    "    num_valid_hands = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            if batch_idx >= 10:  # Quick validation\n",
    "                break\n",
    "                \n",
    "            # GPU preprocessing\n",
    "            patches = gpu_preprocessor(batch['color'])\n",
    "            \n",
    "            # Hand evaluation\n",
    "            with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "                hand_output = hand_encoder(patches)\n",
    "                \n",
    "            hand_gt = batch['hand_joints_3d']\n",
    "            if hand_gt.dim() == 4 and hand_gt.shape[1] == 1:\n",
    "                hand_gt = hand_gt.squeeze(1)\n",
    "            \n",
    "            valid_hands = ~torch.all(hand_gt.view(hand_gt.shape[0], -1) == -1, dim=1)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                hand_loss = mse_loss(\n",
    "                    hand_output['joints_3d'][valid_hands],\n",
    "                    hand_gt[valid_hands]\n",
    "                )\n",
    "                \n",
    "                # MPJPE metric\n",
    "                mpjpe = (hand_output['joints_3d'][valid_hands] - hand_gt[valid_hands]).norm(dim=-1).mean()\n",
    "                \n",
    "                total_loss += hand_loss.item()\n",
    "                total_mpjpe += mpjpe.item() * valid_hands.sum().item()\n",
    "                num_valid_hands += valid_hands.sum().item()\n",
    "            \n",
    "            num_batches += 1\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / max(num_batches, 1),\n",
    "        'mpjpe': total_mpjpe / max(num_valid_hands, 1) if num_valid_hands > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Stats Function\n",
    "def print_gpu_stats():\n",
    "    \"\"\"Print current GPU statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"GPU Statistics:\")\n",
    "        print(f\"  Memory Allocated: {allocated:.1f} GB / {total:.1f} GB ({allocated/total*100:.1f}%)\")\n",
    "        print(f\"  Memory Reserved: {reserved:.1f} GB\")\n",
    "        \n",
    "        # Try to get utilization\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,power.draw,power.limit', \n",
    "                                   '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                gpu_util, power_draw, power_limit = result.stdout.strip().split(', ')\n",
    "                print(f\"  GPU Utilization: {gpu_util}%\")\n",
    "                print(f\"  Power Draw: {power_draw}W / {power_limit}W ({float(power_draw)/float(power_limit)*100:.1f}%)\")\n",
    "        except:\n",
    "            pass\n",
    "        print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting H200 optimized training...\n",
      "Effective batch size: 512\n",
      "Mixed precision: torch.bfloat16\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "GPU Statistics:\n",
      "  Memory Allocated: 1.3 GB / 150.0 GB (0.9%)\n",
      "  Memory Reserved: 1.4 GB\n",
      "  GPU Utilization: 0%\n",
      "  Power Draw: 114.15W / 700.00W (16.3%)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47afb9fe3a474c77821ef68acaa5ca3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1818 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m start_time = time.time()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(epoch)\u001b[39m\n\u001b[32m     17\u001b[39m optimizer_contact.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     19\u001b[39m progress_bar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Data loading time\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_start\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_start\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env2.0/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env2.0/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env2.0/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env2.0/lib/python3.12/site-packages/torch/utils/data/dataloader.py:759\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    757\u001b[39m data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     data = \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env2.0/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py:75\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.MutableMapping):\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001b[39;00m\n\u001b[32m     73\u001b[39m     clone = copy.copy(data)\n\u001b[32m     74\u001b[39m     clone.update(\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         {k: \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m data.items()}\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env2.0/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py:64\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpin_memory\u001b[39m(data, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m     66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mRuntimeError\u001b[39m: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned"
     ]
    }
   ],
   "source": [
    "# Run H200 Optimized Training\n",
    "print(\"Starting H200 optimized training...\")\n",
    "print(f\"Effective batch size: {config['batch_size'] * config['accumulation_steps']}\")\n",
    "print(f\"Mixed precision: {config['amp_dtype']}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_mpjpe': [],\n",
    "    'throughput': []\n",
    "}\n",
    "\n",
    "# Initial GPU stats\n",
    "print_gpu_stats()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config['num_epochs']):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate()\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_mpjpe'].append(val_metrics['mpjpe'])\n",
    "    \n",
    "    # Calculate throughput\n",
    "    epoch_time = time.time() - start_time\n",
    "    samples_processed = len(train_loader) * config['batch_size']\n",
    "    throughput = samples_processed / epoch_time\n",
    "    history['throughput'].append(throughput)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{config['num_epochs']} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val MPJPE: {val_metrics['mpjpe']*1000:.2f}mm\")\n",
    "    print(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
    "    print(f\"  Throughput: {throughput:.1f} samples/s\")\n",
    "    print_gpu_stats()\n",
    "\n",
    "print(\"\\n✓ H200 optimized training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot([x * 1000 for x in history['val_mpjpe']], label='Val MPJPE (mm)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MPJPE (mm)')\n",
    "plt.title('Validation Hand Pose Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['throughput'], label='Throughput')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Samples/sec')\n",
    "plt.title('Training Throughput')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints\n",
    "checkpoint_dir = 'checkpoints/h200_optimized'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Save encoder states\n",
    "torch.save({\n",
    "    'model_state_dict': hand_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_hand.state_dict(),\n",
    "    'config': config,\n",
    "    'history': history\n",
    "}, os.path.join(checkpoint_dir, 'hand_encoder.pth'))\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': object_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_object.state_dict(),\n",
    "    'config': config\n",
    "}, os.path.join(checkpoint_dir, 'object_encoder.pth'))\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': contact_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_contact.state_dict(),\n",
    "    'config': config\n",
    "}, os.path.join(checkpoint_dir, 'contact_encoder.pth'))\n",
    "\n",
    "print(f\"✓ Checkpoints saved to {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-Only Dataset Approach - Maximum Performance\n",
    "\n",
    "This section implements a GPU-only dataset that caches everything in GPU memory, eliminating ALL CPU-GPU transfers during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GPU-only datasets...\n",
      "This will cache 50000 training samples in GPU memory\n",
      "First run will be slow (preprocessing), subsequent runs will be instant\n",
      "\n",
      "Current GPU memory: 3.2GB\n"
     ]
    }
   ],
   "source": [
    "# Import GPU-only dataset\n",
    "from data.gpu_only_dataset import GPUOnlyDataset, GPUBatchGenerator\n",
    "\n",
    "# GPU-only configuration\n",
    "gpu_config = {\n",
    "    'max_samples_train': 50000,  # Adjust based on GPU memory (50k samples ≈ 50GB)\n",
    "    'max_samples_val': 5000,\n",
    "    'batch_size': 1024,  # Large batch size\n",
    "    'image_size': (224, 224),\n",
    "    'cache_path': 'gpu_cache',  # Cache preprocessed data\n",
    "    'dtype': torch.float32,  # Use bfloat16 to fit more samples\n",
    "}\n",
    "\n",
    "print(\"Creating GPU-only datasets...\")\n",
    "print(f\"This will cache {gpu_config['max_samples_train']} training samples in GPU memory\")\n",
    "print(\"First run will be slow (preprocessing), subsequent runs will be instant\")\n",
    "\n",
    "# Clear GPU memory first\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(f\"\\nCurrent GPU memory: {torch.cuda.memory_allocated()/1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GPU dataset for s0_train...\n",
      "Allocating GPU memory for 50000 samples...\n",
      "Loading and preprocessing data...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (48) must match the existing size (51) at non-singleton dimension 0.  Target sizes: [48].  Tensor sizes: [51]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create GPU-only datasets\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# These load and preprocess everything once, then keep it in GPU memory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m gpu_train_dataset = \u001b[43mGPUOnlyDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms0_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpu_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_samples_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpu_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpu_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdtype\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpu_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcache_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m gpu_val_dataset = GPUOnlyDataset(\n\u001b[32m     14\u001b[39m     split=\u001b[33m'\u001b[39m\u001b[33ms0_val\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     max_samples=gpu_config[\u001b[33m'\u001b[39m\u001b[33mmax_samples_val\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     cache_path=gpu_config[\u001b[33m'\u001b[39m\u001b[33mcache_path\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Create batch generators (zero-copy from GPU memory)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/231nProjectV2/Video_Manipulation_Transformer/data/gpu_only_dataset.py:50\u001b[39m, in \u001b[36mGPUOnlyDataset.__init__\u001b[39m\u001b[34m(self, split, max_samples, image_size, device, dtype, cache_path)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBuilding GPU dataset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cache_path:\n\u001b[32m     52\u001b[39m         \u001b[38;5;28mself\u001b[39m._save_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/231nProjectV2/Video_Manipulation_Transformer/data/gpu_only_dataset.py:123\u001b[39m, in \u001b[36mGPUOnlyDataset._build_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mpose_m\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[32m    122\u001b[39m     pose = torch.from_numpy(labels[\u001b[33m'\u001b[39m\u001b[33mpose_m\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhand_pose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m = pose.to(\u001b[38;5;28mself\u001b[39m.device, dtype=\u001b[38;5;28mself\u001b[39m.dtype)\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Object data\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mpose_y\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m labels:\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (48) must match the existing size (51) at non-singleton dimension 0.  Target sizes: [48].  Tensor sizes: [51]"
     ]
    }
   ],
   "source": [
    "# Create GPU-only datasets\n",
    "# These load and preprocess everything once, then keep it in GPU memory\n",
    "\n",
    "gpu_train_dataset = GPUOnlyDataset(\n",
    "    split='s0_train',\n",
    "    max_samples=gpu_config['max_samples_train'],\n",
    "    image_size=gpu_config['image_size'],\n",
    "    device='cuda',\n",
    "    dtype=gpu_config['dtype'],\n",
    "    cache_path=gpu_config['cache_path']\n",
    ")\n",
    "\n",
    "gpu_val_dataset = GPUOnlyDataset(\n",
    "    split='s0_val',\n",
    "    max_samples=gpu_config['max_samples_val'],\n",
    "    image_size=gpu_config['image_size'],\n",
    "    device='cuda',\n",
    "    dtype=gpu_config['dtype'],\n",
    "    cache_path=gpu_config['cache_path']\n",
    ")\n",
    "\n",
    "# Create batch generators (zero-copy from GPU memory)\n",
    "gpu_train_loader = GPUBatchGenerator(gpu_train_dataset, batch_size=gpu_config['batch_size'], shuffle=True)\n",
    "gpu_val_loader = GPUBatchGenerator(gpu_val_dataset, batch_size=gpu_config['batch_size']//2, shuffle=False)\n",
    "\n",
    "print(f\"\\n✓ GPU-only datasets created:\")\n",
    "print(f\"  Train: {len(gpu_train_dataset)} samples cached in GPU\")\n",
    "print(f\"  Val: {len(gpu_val_dataset)} samples cached in GPU\")\n",
    "print(f\"  GPU Memory Used: {torch.cuda.memory_allocated()/1e9:.1f} GB\")\n",
    "print(f\"  Batches per epoch: {len(gpu_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-only training function\n",
    "def gpu_only_train_epoch(epoch, model_hand, model_object, model_contact, \n",
    "                        opt_hand, opt_object, opt_contact, \n",
    "                        loader, preprocessor):\n",
    "    \"\"\"Training with zero CPU operations - everything stays on GPU\"\"\"\n",
    "    model_hand.train()\n",
    "    model_object.train()\n",
    "    model_contact.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Progress bar\n",
    "    progress_bar = tqdm(loader, desc=f'GPU-Only Epoch {epoch+1}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Everything is already on GPU - no transfers!\n",
    "        \n",
    "        # Create patches directly on GPU\n",
    "        with torch.no_grad():\n",
    "            patches = preprocessor.create_patches_batch(batch['color'])\n",
    "        \n",
    "        # Zero gradients\n",
    "        opt_hand.zero_grad(set_to_none=True)\n",
    "        opt_object.zero_grad(set_to_none=True)\n",
    "        opt_contact.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Forward passes with mixed precision\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            # Hand encoder\n",
    "            hand_output = model_hand(patches)\n",
    "            hand_gt = batch['hand_joints_3d']\n",
    "            valid_hands = ~(hand_gt.view(hand_gt.shape[0], -1) == -1).all(dim=1)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                hand_loss = F.mse_loss(hand_output['joints_3d'][valid_hands], hand_gt[valid_hands])\n",
    "            else:\n",
    "                hand_loss = torch.tensor(0.0, device='cuda')\n",
    "            \n",
    "            # Object encoder\n",
    "            object_output = model_object(patches, object_ids=batch.get('ycb_ids'))\n",
    "            object_loss = torch.tensor(0.0, device='cuda')\n",
    "            \n",
    "            if 'object_poses' in batch and batch['object_poses'].shape[1] > 0:\n",
    "                valid_objects = ~(batch['object_poses'] == 0).all(dim=(2, 3))\n",
    "                if valid_objects.any():\n",
    "                    object_positions_gt = batch['object_poses'][:, :, :3, 3]\n",
    "                    num_pred = min(object_output['positions'].shape[1], batch['object_poses'].shape[1])\n",
    "                    valid_mask = valid_objects[:, :num_pred]\n",
    "                    \n",
    "                    if valid_mask.any():\n",
    "                        pred_pos = object_output['positions'][:, :num_pred][valid_mask]\n",
    "                        gt_pos = object_positions_gt[:, :num_pred][valid_mask]\n",
    "                        object_loss = F.mse_loss(pred_pos, gt_pos)\n",
    "            \n",
    "            # Contact encoder\n",
    "            contact_output = model_contact(\n",
    "                hand_output['features'].detach(),\n",
    "                object_output['features'].detach()\n",
    "            )\n",
    "            \n",
    "            # Total loss\n",
    "            total_batch_loss = hand_loss + object_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_batch_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model_hand.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model_object.parameters(), 1.0)\n",
    "        \n",
    "        # Optimizer steps\n",
    "        opt_hand.step()\n",
    "        opt_object.step()\n",
    "        opt_contact.step()\n",
    "        \n",
    "        # Metrics\n",
    "        total_loss += total_batch_loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        if batch_idx % 5 == 0:\n",
    "            gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "            elapsed = time.time() - epoch_start\n",
    "            samples_per_sec = (batch_idx + 1) * gpu_config['batch_size'] / elapsed\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{total_batch_loss.item():.4f}',\n",
    "                'gpu': f'{gpu_mem:.1f}GB',\n",
    "                'speed': f'{samples_per_sec:.0f}/s'\n",
    "            })\n",
    "    \n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "def gpu_only_validate(model_hand, loader, preprocessor):\n",
    "    \"\"\"Fast validation on GPU\"\"\"\n",
    "    model_hand.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_mpjpe = 0\n",
    "    num_batches = 0\n",
    "    num_valid = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(loader):\n",
    "            if batch_idx >= 10:  # Quick validation\n",
    "                break\n",
    "            \n",
    "            # GPU preprocessing\n",
    "            patches = preprocessor.create_patches_batch(batch['color'])\n",
    "            \n",
    "            # Forward pass\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                hand_output = model_hand(patches)\n",
    "            \n",
    "            hand_gt = batch['hand_joints_3d']\n",
    "            valid_hands = ~(hand_gt.view(hand_gt.shape[0], -1) == -1).all(dim=1)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                loss = F.mse_loss(hand_output['joints_3d'][valid_hands], hand_gt[valid_hands])\n",
    "                mpjpe = (hand_output['joints_3d'][valid_hands] - hand_gt[valid_hands]).norm(dim=-1).mean()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_mpjpe += mpjpe.item() * valid_hands.sum().item()\n",
    "                num_valid += valid_hands.sum().item()\n",
    "            \n",
    "            num_batches += 1\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / max(num_batches, 1),\n",
    "        'mpjpe': total_mpjpe / max(num_valid, 1) if num_valid > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GPU-Only Training\n",
    "print(\"Starting GPU-Only Training with cached dataset...\")\n",
    "print(f\"Batch size: {gpu_config['batch_size']}\")\n",
    "print(f\"Zero CPU operations - everything on GPU!\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create fresh optimizers for GPU-only training\n",
    "gpu_opt_hand = optim.AdamW(hand_encoder.parameters(), lr=2e-3)\n",
    "gpu_opt_object = optim.AdamW(object_encoder.parameters(), lr=2e-3)\n",
    "gpu_opt_contact = optim.AdamW(contact_encoder.parameters(), lr=2e-3)\n",
    "\n",
    "# GPU-only training history\n",
    "gpu_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_mpjpe': [],\n",
    "    'throughput': []\n",
    "}\n",
    "\n",
    "# Initial GPU stats\n",
    "print_gpu_stats()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3  # Quick test\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = gpu_only_train_epoch(\n",
    "        epoch, \n",
    "        hand_encoder, object_encoder, contact_encoder,\n",
    "        gpu_opt_hand, gpu_opt_object, gpu_opt_contact,\n",
    "        gpu_train_loader, gpu_preprocessor\n",
    "    )\n",
    "    gpu_history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = gpu_only_validate(hand_encoder, gpu_val_loader, gpu_preprocessor)\n",
    "    gpu_history['val_loss'].append(val_metrics['loss'])\n",
    "    gpu_history['val_mpjpe'].append(val_metrics['mpjpe'])\n",
    "    \n",
    "    # Calculate throughput\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    total_samples = len(gpu_train_loader) * gpu_config['batch_size']\n",
    "    throughput = total_samples / epoch_time\n",
    "    gpu_history['throughput'].append(throughput)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val MPJPE: {val_metrics['mpjpe']*1000:.2f}mm\")\n",
    "    print(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
    "    print(f\"  Throughput: {throughput:.0f} samples/s\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n",
    "    \n",
    "    # Check GPU utilization\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', \n",
    "                               '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            gpu_util = float(result.stdout.strip())\n",
    "            print(f\"  GPU Utilization: {gpu_util}% {'✓' if gpu_util > 80 else '⚠️'}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\n✓ GPU-Only training completed!\")\n",
    "print_gpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance: Standard vs GPU-Only\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'history' in globals() and 'throughput' in history and len(history['throughput']) > 0:\n",
    "    standard_throughput = np.mean(history['throughput'])\n",
    "    print(f\"Standard DataLoader: {standard_throughput:.0f} samples/s\")\n",
    "else:\n",
    "    print(\"Standard DataLoader: Not run\")\n",
    "\n",
    "if 'gpu_history' in globals() and 'throughput' in gpu_history and len(gpu_history['throughput']) > 0:\n",
    "    gpu_throughput = np.mean(gpu_history['throughput'])\n",
    "    print(f\"GPU-Only Dataset:    {gpu_throughput:.0f} samples/s\")\n",
    "    \n",
    "    if 'standard_throughput' in locals():\n",
    "        speedup = gpu_throughput / standard_throughput\n",
    "        print(f\"\\nSpeedup: {speedup:.1f}x faster with GPU-only approach!\")\n",
    "else:\n",
    "    print(\"GPU-Only Dataset: Not run\")\n",
    "\n",
    "# Plot comparison if both were run\n",
    "if 'history' in globals() and 'gpu_history' in globals():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    if len(history['train_loss']) > 0:\n",
    "        plt.plot(history['train_loss'], label='Standard', marker='o')\n",
    "    if len(gpu_history['train_loss']) > 0:\n",
    "        plt.plot(gpu_history['train_loss'], label='GPU-Only', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if len(history['throughput']) > 0:\n",
    "        plt.bar(['Standard'], [np.mean(history['throughput'])], color='blue', alpha=0.6)\n",
    "    if len(gpu_history['throughput']) > 0:\n",
    "        plt.bar(['GPU-Only'], [np.mean(gpu_history['throughput'])], color='green', alpha=0.6)\n",
    "    plt.ylabel('Samples/second')\n",
    "    plt.title('Throughput Comparison')\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Maximum GPU Utilization\n",
    "\n",
    "### 1. **Adjust Dataset Cache Size**\n",
    "```python\n",
    "# For 140GB H200, you can cache more samples:\n",
    "max_samples_train = 100000  # ~100GB\n",
    "max_samples_train = 150000  # ~150GB (if using bfloat16)\n",
    "```\n",
    "\n",
    "### 2. **Use BFloat16 for More Samples**\n",
    "```python\n",
    "dtype = torch.bfloat16  # Half the memory, similar accuracy\n",
    "```\n",
    "\n",
    "### 3. **Increase Batch Size**\n",
    "```python\n",
    "batch_size = 2048  # or even 4096 if memory allows\n",
    "```\n",
    "\n",
    "### 4. **Monitor GPU Usage**\n",
    "Run in another terminal:\n",
    "```bash\n",
    "watch -n 0.5 nvidia-smi\n",
    "```\n",
    "\n",
    "### 5. **Clear Cache Between Runs**\n",
    "```python\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "```\n",
    "\n",
    "### Expected Results with GPU-Only Approach:\n",
    "- **GPU Utilization**: 90%+ (was 20%)\n",
    "- **Memory Usage**: 50-100GB (was 2.5GB)\n",
    "- **Throughput**: 10,000+ samples/s (was ~500)\n",
    "- **Power Draw**: 600W+ (was 172W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}