{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Video-to-Manipulation Transformer: GPU-Only Stage 1 Training\n\nThis notebook implements the fastest GPU-only training approach for maximum performance on H200.\n\n**Key Features:**\n- Entire dataset cached in GPU memory (zero CPU-GPU transfers)\n- Large batch sizes (1024+)\n- BFloat16 mixed precision\n- Compiled models for better performance\n- No DataLoader overhead\n\n**Requirements:**\n- H200 GPU with 140GB memory\n- PyTorch 2.0+ for torch.compile\n- CUDA 12.0+",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "# CRITICAL: Set multiprocessing start method for CUDA\n",
    "import multiprocessing\n",
    "try:\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  # Already set\n",
    "\n",
    "# Set environment\n",
    "os.environ['DEX_YCB_DIR'] = '/home/n231/231nProjectV2/dex-ycb-toolkit/data'\n",
    "\n",
    "# CUDA optimizations for H200\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('.')\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "from models.encoders.hand_encoder import HandPoseEncoder\n",
    "from models.encoders.object_encoder import ObjectPoseEncoder\n",
    "from models.encoders.contact_encoder import ContactDetectionEncoder\n",
    "from data.dexycb_dataset import DexYCBDataset\n",
    "from data.gpu_preprocessing import GPUVideoPreprocessor, FastDataCollator\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H200 Optimized Configuration\n",
    "config = {\n",
    "    # Data settings - maximize throughput\n",
    "    'batch_size': 256,  # Large batch for H200\n",
    "    'num_workers': 0,   # CRITICAL: Set to 0 to avoid CUDA fork error\n",
    "    'pin_memory': True,\n",
    "    'persistent_workers': False,  # Not needed with 0 workers\n",
    "    \n",
    "    # Model settings - scale up\n",
    "    'patch_size': 16,\n",
    "    'image_size': [224, 224],\n",
    "    'hand_hidden_dim': 1024,  # 2x larger\n",
    "    'object_hidden_dim': 1024,\n",
    "    'contact_hidden_dim': 512,\n",
    "    'hand_layers': 12,  # 2x deeper\n",
    "    'object_layers': 12,\n",
    "    'contact_layers': 8,\n",
    "    \n",
    "    # Training settings\n",
    "    'learning_rate': 5e-4,\n",
    "    'num_epochs': 5,\n",
    "    'grad_clip': 1.0,\n",
    "    'warmup_steps': 100,\n",
    "    'accumulation_steps': 2,  # Effective batch = 512\n",
    "    \n",
    "    # Mixed precision\n",
    "    'use_amp': True,\n",
    "    'amp_dtype': torch.bfloat16,\n",
    "    \n",
    "    # Logging\n",
    "    'log_interval': 10,\n",
    "    'val_interval': 50\n",
    "}\n",
    "\n",
    "print(\"H200 Configuration loaded\")\n",
    "print(f\"Effective batch size: {config['batch_size'] * config['accumulation_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "\n",
    "train_dataset = DexYCBDataset(split='s0_train', max_objects=10)\n",
    "val_dataset = DexYCBDataset(split='s0_val', max_objects=10)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(val_dataset):,}\")\n",
    "\n",
    "# Create GPU-accelerated data loaders\n",
    "# Use FastDataCollator to move data directly to GPU\n",
    "collate_fn = FastDataCollator(device='cuda')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],  # 0 to avoid CUDA fork\n",
    "    pin_memory=config['pin_memory'],\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Always 0 for validation\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Train batches per epoch: {len(train_loader)}\")\n",
    "print(\"✓ Data loaders created with GPU acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled-up models for H200\n",
    "print(\"Creating scaled-up models...\")\n",
    "\n",
    "patch_dim = 3 * config['patch_size'] * config['patch_size']\n",
    "\n",
    "# Large hand encoder\n",
    "hand_encoder = HandPoseEncoder(\n",
    "    input_dim=patch_dim,\n",
    "    hidden_dim=config['hand_hidden_dim'],\n",
    "    num_layers=config['hand_layers'],\n",
    "    num_heads=16,\n",
    "    mlp_dim=4096,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Large object encoder\n",
    "object_encoder = ObjectPoseEncoder(\n",
    "    input_dim=patch_dim,\n",
    "    hidden_dim=config['object_hidden_dim'],\n",
    "    num_layers=config['object_layers'],\n",
    "    num_heads=16,\n",
    "    mlp_dim=4096,\n",
    "    dropout=0.1,\n",
    "    max_objects=10\n",
    ").to(device)\n",
    "\n",
    "# Large contact encoder\n",
    "contact_encoder = ContactDetectionEncoder(\n",
    "    input_dim=patch_dim,\n",
    "    hidden_dim=config['contact_hidden_dim'],\n",
    "    num_layers=config['contact_layers'],\n",
    "    num_heads=16,\n",
    "    mlp_dim=2048,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Compile models for better performance\n",
    "if hasattr(torch, 'compile'):\n",
    "    print(\"Compiling models...\")\n",
    "    hand_encoder = torch.compile(hand_encoder, mode='default')\n",
    "    object_encoder = torch.compile(object_encoder, mode='default')\n",
    "    contact_encoder = torch.compile(contact_encoder, mode='default')\n",
    "\n",
    "# Model info\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = (count_parameters(hand_encoder) + \n",
    "                count_parameters(object_encoder) + \n",
    "                count_parameters(contact_encoder))\n",
    "\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Hand encoder: {count_parameters(hand_encoder)/1e6:.1f}M\")\n",
    "print(f\"  Object encoder: {count_parameters(object_encoder)/1e6:.1f}M\")\n",
    "print(f\"  Contact encoder: {count_parameters(contact_encoder)/1e6:.1f}M\")\n",
    "print(f\"  Total: {total_params/1e6:.1f}M\")\n",
    "\n",
    "print(f\"\\nGPU Memory: {torch.cuda.memory_allocated()/1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GPU preprocessor\n",
    "gpu_preprocessor = GPUVideoPreprocessor(\n",
    "    image_size=tuple(config['image_size']),\n",
    "    patch_size=config['patch_size'],\n",
    "    normalize=True,\n",
    "    device='cuda'\n",
    ").to(device)\n",
    "\n",
    "# Setup optimizers and schedulers\n",
    "optimizer_hand = optim.AdamW(hand_encoder.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "optimizer_object = optim.AdamW(object_encoder.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "optimizer_contact = optim.AdamW(contact_encoder.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "# Mixed precision scalers\n",
    "scaler_hand = GradScaler(enabled=config['use_amp'])\n",
    "scaler_object = GradScaler(enabled=config['use_amp'])\n",
    "scaler_contact = GradScaler(enabled=config['use_amp'])\n",
    "\n",
    "# Loss function\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "print(\"✓ Optimizers and mixed precision configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H200 Optimized Training Function\n",
    "def train_epoch(epoch):\n",
    "    \"\"\"Optimized training for H200 with mixed precision\"\"\"\n",
    "    hand_encoder.train()\n",
    "    object_encoder.train()\n",
    "    contact_encoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    data_time = 0\n",
    "    compute_time = 0\n",
    "    batch_start = time.time()\n",
    "    \n",
    "    # Zero gradients at start\n",
    "    optimizer_hand.zero_grad(set_to_none=True)\n",
    "    optimizer_object.zero_grad(set_to_none=True)\n",
    "    optimizer_contact.zero_grad(set_to_none=True)\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Data loading time\n",
    "        data_time += time.time() - batch_start\n",
    "        compute_start = time.time()\n",
    "        \n",
    "        # All data is already on GPU thanks to FastDataCollator\n",
    "        # Process images through GPU preprocessor\n",
    "        with torch.no_grad():\n",
    "            patches = gpu_preprocessor(batch['color'])\n",
    "        \n",
    "        # Prepare ground truth\n",
    "        hand_gt = batch['hand_joints_3d']\n",
    "        if hand_gt.dim() == 4 and hand_gt.shape[1] == 1:\n",
    "            hand_gt = hand_gt.squeeze(1)\n",
    "        \n",
    "        valid_hands = ~torch.all(hand_gt.view(hand_gt.shape[0], -1) == -1, dim=1)\n",
    "        \n",
    "        # === MIXED PRECISION FORWARD PASSES ===\n",
    "        \n",
    "        # Hand encoder\n",
    "        with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "            hand_output = hand_encoder(patches)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                hand_loss = mse_loss(\n",
    "                    hand_output['joints_3d'][valid_hands],\n",
    "                    hand_gt[valid_hands]\n",
    "                ) / config['accumulation_steps']\n",
    "            else:\n",
    "                hand_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "        \n",
    "        # Backward for hand\n",
    "        scaler_hand.scale(hand_loss).backward()\n",
    "        \n",
    "        # Object encoder\n",
    "        with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "            object_output = object_encoder(patches, object_ids=batch.get('ycb_ids', None))\n",
    "            \n",
    "            # Object loss\n",
    "            object_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "            if batch['object_poses'].shape[1] > 0:\n",
    "                valid_objects = ~torch.all(batch['object_poses'] == 0, dim=(2, 3))\n",
    "                if valid_objects.any():\n",
    "                    object_positions_gt = batch['object_poses'][:, :, :3, 3]\n",
    "                    num_pred_objects = min(object_output['positions'].shape[1], batch['object_poses'].shape[1])\n",
    "                    valid_mask = valid_objects[:, :num_pred_objects]\n",
    "                    \n",
    "                    if valid_mask.any():\n",
    "                        pred_positions = object_output['positions'][:, :num_pred_objects]\n",
    "                        gt_positions = object_positions_gt[:, :num_pred_objects]\n",
    "                        pred_flat = pred_positions[valid_mask]\n",
    "                        gt_flat = gt_positions[valid_mask]\n",
    "                        object_loss = mse_loss(pred_flat, gt_flat) / config['accumulation_steps']\n",
    "        \n",
    "        # Backward for object\n",
    "        scaler_object.scale(object_loss).backward()\n",
    "        \n",
    "        # Contact encoder (no ground truth)\n",
    "        with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "            contact_output = contact_encoder(\n",
    "                hand_output['features'].detach(),\n",
    "                object_output['features'].detach()\n",
    "            )\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (batch_idx + 1) % config['accumulation_steps'] == 0:\n",
    "            # Unscale and clip gradients\n",
    "            scaler_hand.unscale_(optimizer_hand)\n",
    "            scaler_object.unscale_(optimizer_object)\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(hand_encoder.parameters(), config['grad_clip'])\n",
    "            torch.nn.utils.clip_grad_norm_(object_encoder.parameters(), config['grad_clip'])\n",
    "            \n",
    "            # Optimizer steps\n",
    "            scaler_hand.step(optimizer_hand)\n",
    "            scaler_object.step(optimizer_object)\n",
    "            scaler_contact.step(optimizer_contact)\n",
    "            \n",
    "            # Update scalers\n",
    "            scaler_hand.update()\n",
    "            scaler_object.update()\n",
    "            scaler_contact.update()\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer_hand.zero_grad(set_to_none=True)\n",
    "            optimizer_object.zero_grad(set_to_none=True)\n",
    "            optimizer_contact.zero_grad(set_to_none=True)\n",
    "        \n",
    "        compute_time += time.time() - compute_start\n",
    "        \n",
    "        # Update metrics\n",
    "        total_loss += hand_loss.item() * config['accumulation_steps'] + object_loss.item() * config['accumulation_steps']\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "        samples_per_sec = (batch_idx + 1) * config['batch_size'] / (time.time() - progress_bar.start_t)\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{(hand_loss.item() + object_loss.item()) * config[\"accumulation_steps\"]:.4f}',\n",
    "            'gpu_gb': f'{gpu_mem:.1f}',\n",
    "            'speed': f'{samples_per_sec:.0f}',\n",
    "        })\n",
    "        \n",
    "        # Log periodically\n",
    "        if (batch_idx + 1) % config['log_interval'] == 0:\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] \"\n",
    "                  f\"GPU: {gpu_mem:.1f}GB | \"\n",
    "                  f\"Speed: {samples_per_sec:.0f} samples/s\")\n",
    "        \n",
    "        batch_start = time.time()\n",
    "    \n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "def validate():\n",
    "    \"\"\"Fast validation\"\"\"\n",
    "    hand_encoder.eval()\n",
    "    object_encoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_mpjpe = 0\n",
    "    num_batches = 0\n",
    "    num_valid_hands = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            if batch_idx >= 10:  # Quick validation\n",
    "                break\n",
    "                \n",
    "            # GPU preprocessing\n",
    "            patches = gpu_preprocessor(batch['color'])\n",
    "            \n",
    "            # Hand evaluation\n",
    "            with autocast(device_type='cuda', dtype=config['amp_dtype']):\n",
    "                hand_output = hand_encoder(patches)\n",
    "                \n",
    "            hand_gt = batch['hand_joints_3d']\n",
    "            if hand_gt.dim() == 4 and hand_gt.shape[1] == 1:\n",
    "                hand_gt = hand_gt.squeeze(1)\n",
    "            \n",
    "            valid_hands = ~torch.all(hand_gt.view(hand_gt.shape[0], -1) == -1, dim=1)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                hand_loss = mse_loss(\n",
    "                    hand_output['joints_3d'][valid_hands],\n",
    "                    hand_gt[valid_hands]\n",
    "                )\n",
    "                \n",
    "                # MPJPE metric\n",
    "                mpjpe = (hand_output['joints_3d'][valid_hands] - hand_gt[valid_hands]).norm(dim=-1).mean()\n",
    "                \n",
    "                total_loss += hand_loss.item()\n",
    "                total_mpjpe += mpjpe.item() * valid_hands.sum().item()\n",
    "                num_valid_hands += valid_hands.sum().item()\n",
    "            \n",
    "            num_batches += 1\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / max(num_batches, 1),\n",
    "        'mpjpe': total_mpjpe / max(num_valid_hands, 1) if num_valid_hands > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Stats Function\n",
    "def print_gpu_stats():\n",
    "    \"\"\"Print current GPU statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"GPU Statistics:\")\n",
    "        print(f\"  Memory Allocated: {allocated:.1f} GB / {total:.1f} GB ({allocated/total*100:.1f}%)\")\n",
    "        print(f\"  Memory Reserved: {reserved:.1f} GB\")\n",
    "        \n",
    "        # Try to get utilization\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,power.draw,power.limit', \n",
    "                                   '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                gpu_util, power_draw, power_limit = result.stdout.strip().split(', ')\n",
    "                print(f\"  GPU Utilization: {gpu_util}%\")\n",
    "                print(f\"  Power Draw: {power_draw}W / {power_limit}W ({float(power_draw)/float(power_limit)*100:.1f}%)\")\n",
    "        except:\n",
    "            pass\n",
    "        print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run H200 Optimized Training\n",
    "print(\"Starting H200 optimized training...\")\n",
    "print(f\"Effective batch size: {config['batch_size'] * config['accumulation_steps']}\")\n",
    "print(f\"Mixed precision: {config['amp_dtype']}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_mpjpe': [],\n",
    "    'throughput': []\n",
    "}\n",
    "\n",
    "# Initial GPU stats\n",
    "print_gpu_stats()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config['num_epochs']):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate()\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_mpjpe'].append(val_metrics['mpjpe'])\n",
    "    \n",
    "    # Calculate throughput\n",
    "    epoch_time = time.time() - start_time\n",
    "    samples_processed = len(train_loader) * config['batch_size']\n",
    "    throughput = samples_processed / epoch_time\n",
    "    history['throughput'].append(throughput)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{config['num_epochs']} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val MPJPE: {val_metrics['mpjpe']*1000:.2f}mm\")\n",
    "    print(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
    "    print(f\"  Throughput: {throughput:.1f} samples/s\")\n",
    "    print_gpu_stats()\n",
    "\n",
    "print(\"\\n✓ H200 optimized training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot([x * 1000 for x in history['val_mpjpe']], label='Val MPJPE (mm)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MPJPE (mm)')\n",
    "plt.title('Validation Hand Pose Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['throughput'], label='Throughput')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Samples/sec')\n",
    "plt.title('Training Throughput')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints\n",
    "checkpoint_dir = 'checkpoints/h200_optimized'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Save encoder states\n",
    "torch.save({\n",
    "    'model_state_dict': hand_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_hand.state_dict(),\n",
    "    'config': config,\n",
    "    'history': history\n",
    "}, os.path.join(checkpoint_dir, 'hand_encoder.pth'))\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': object_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_object.state_dict(),\n",
    "    'config': config\n",
    "}, os.path.join(checkpoint_dir, 'object_encoder.pth'))\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': contact_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_contact.state_dict(),\n",
    "    'config': config\n",
    "}, os.path.join(checkpoint_dir, 'contact_encoder.pth'))\n",
    "\n",
    "print(f\"✓ Checkpoints saved to {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-Only Dataset Approach - Maximum Performance\n",
    "\n",
    "This section implements a GPU-only dataset that caches everything in GPU memory, eliminating ALL CPU-GPU transfers during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GPU-only dataset\n",
    "from data.gpu_only_dataset import GPUOnlyDataset, GPUBatchGenerator\n",
    "\n",
    "# GPU-only configuration\n",
    "gpu_config = {\n",
    "    'max_samples_train': 50000,  # Adjust based on GPU memory (50k samples ≈ 50GB)\n",
    "    'max_samples_val': 5000,\n",
    "    'batch_size': 1024,  # Large batch size\n",
    "    'image_size': (224, 224),\n",
    "    'cache_path': 'gpu_cache',  # Cache preprocessed data\n",
    "    'dtype': torch.float32,  # Use bfloat16 to fit more samples\n",
    "}\n",
    "\n",
    "print(\"Creating GPU-only datasets...\")\n",
    "print(f\"This will cache {gpu_config['max_samples_train']} training samples in GPU memory\")\n",
    "print(\"First run will be slow (preprocessing), subsequent runs will be instant\")\n",
    "\n",
    "# Clear GPU memory first\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(f\"\\nCurrent GPU memory: {torch.cuda.memory_allocated()/1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GPU-only datasets\n",
    "# These load and preprocess everything once, then keep it in GPU memory\n",
    "\n",
    "gpu_train_dataset = GPUOnlyDataset(\n",
    "    split='s0_train',\n",
    "    max_samples=gpu_config['max_samples_train'],\n",
    "    image_size=gpu_config['image_size'],\n",
    "    device='cuda',\n",
    "    dtype=gpu_config['dtype'],\n",
    "    cache_path=gpu_config['cache_path']\n",
    ")\n",
    "\n",
    "gpu_val_dataset = GPUOnlyDataset(\n",
    "    split='s0_val',\n",
    "    max_samples=gpu_config['max_samples_val'],\n",
    "    image_size=gpu_config['image_size'],\n",
    "    device='cuda',\n",
    "    dtype=gpu_config['dtype'],\n",
    "    cache_path=gpu_config['cache_path']\n",
    ")\n",
    "\n",
    "# Create batch generators (zero-copy from GPU memory)\n",
    "gpu_train_loader = GPUBatchGenerator(gpu_train_dataset, batch_size=gpu_config['batch_size'], shuffle=True)\n",
    "gpu_val_loader = GPUBatchGenerator(gpu_val_dataset, batch_size=gpu_config['batch_size']//2, shuffle=False)\n",
    "\n",
    "print(f\"\\n✓ GPU-only datasets created:\")\n",
    "print(f\"  Train: {len(gpu_train_dataset)} samples cached in GPU\")\n",
    "print(f\"  Val: {len(gpu_val_dataset)} samples cached in GPU\")\n",
    "print(f\"  GPU Memory Used: {torch.cuda.memory_allocated()/1e9:.1f} GB\")\n",
    "print(f\"  Batches per epoch: {len(gpu_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-only training function\n",
    "def gpu_only_train_epoch(epoch, model_hand, model_object, model_contact, \n",
    "                        opt_hand, opt_object, opt_contact, \n",
    "                        loader, preprocessor):\n",
    "    \"\"\"Training with zero CPU operations - everything stays on GPU\"\"\"\n",
    "    model_hand.train()\n",
    "    model_object.train()\n",
    "    model_contact.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Progress bar\n",
    "    progress_bar = tqdm(loader, desc=f'GPU-Only Epoch {epoch+1}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Everything is already on GPU - no transfers!\n",
    "        \n",
    "        # Create patches directly on GPU\n",
    "        with torch.no_grad():\n",
    "            patches = preprocessor.create_patches_batch(batch['color'])\n",
    "        \n",
    "        # Zero gradients\n",
    "        opt_hand.zero_grad(set_to_none=True)\n",
    "        opt_object.zero_grad(set_to_none=True)\n",
    "        opt_contact.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Forward passes with mixed precision\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            # Hand encoder\n",
    "            hand_output = model_hand(patches)\n",
    "            hand_gt = batch['hand_joints_3d']\n",
    "            valid_hands = ~(hand_gt.view(hand_gt.shape[0], -1) == -1).all(dim=1)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                hand_loss = F.mse_loss(hand_output['joints_3d'][valid_hands], hand_gt[valid_hands])\n",
    "            else:\n",
    "                hand_loss = torch.tensor(0.0, device='cuda')\n",
    "            \n",
    "            # Object encoder\n",
    "            object_output = model_object(patches, object_ids=batch.get('ycb_ids'))\n",
    "            object_loss = torch.tensor(0.0, device='cuda')\n",
    "            \n",
    "            if 'object_poses' in batch and batch['object_poses'].shape[1] > 0:\n",
    "                valid_objects = ~(batch['object_poses'] == 0).all(dim=(2, 3))\n",
    "                if valid_objects.any():\n",
    "                    object_positions_gt = batch['object_poses'][:, :, :3, 3]\n",
    "                    num_pred = min(object_output['positions'].shape[1], batch['object_poses'].shape[1])\n",
    "                    valid_mask = valid_objects[:, :num_pred]\n",
    "                    \n",
    "                    if valid_mask.any():\n",
    "                        pred_pos = object_output['positions'][:, :num_pred][valid_mask]\n",
    "                        gt_pos = object_positions_gt[:, :num_pred][valid_mask]\n",
    "                        object_loss = F.mse_loss(pred_pos, gt_pos)\n",
    "            \n",
    "            # Contact encoder\n",
    "            contact_output = model_contact(\n",
    "                hand_output['features'].detach(),\n",
    "                object_output['features'].detach()\n",
    "            )\n",
    "            \n",
    "            # Total loss\n",
    "            total_batch_loss = hand_loss + object_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_batch_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model_hand.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model_object.parameters(), 1.0)\n",
    "        \n",
    "        # Optimizer steps\n",
    "        opt_hand.step()\n",
    "        opt_object.step()\n",
    "        opt_contact.step()\n",
    "        \n",
    "        # Metrics\n",
    "        total_loss += total_batch_loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        if batch_idx % 5 == 0:\n",
    "            gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "            elapsed = time.time() - epoch_start\n",
    "            samples_per_sec = (batch_idx + 1) * gpu_config['batch_size'] / elapsed\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{total_batch_loss.item():.4f}',\n",
    "                'gpu': f'{gpu_mem:.1f}GB',\n",
    "                'speed': f'{samples_per_sec:.0f}/s'\n",
    "            })\n",
    "    \n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "def gpu_only_validate(model_hand, loader, preprocessor):\n",
    "    \"\"\"Fast validation on GPU\"\"\"\n",
    "    model_hand.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_mpjpe = 0\n",
    "    num_batches = 0\n",
    "    num_valid = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(loader):\n",
    "            if batch_idx >= 10:  # Quick validation\n",
    "                break\n",
    "            \n",
    "            # GPU preprocessing\n",
    "            patches = preprocessor.create_patches_batch(batch['color'])\n",
    "            \n",
    "            # Forward pass\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                hand_output = model_hand(patches)\n",
    "            \n",
    "            hand_gt = batch['hand_joints_3d']\n",
    "            valid_hands = ~(hand_gt.view(hand_gt.shape[0], -1) == -1).all(dim=1)\n",
    "            \n",
    "            if valid_hands.any():\n",
    "                loss = F.mse_loss(hand_output['joints_3d'][valid_hands], hand_gt[valid_hands])\n",
    "                mpjpe = (hand_output['joints_3d'][valid_hands] - hand_gt[valid_hands]).norm(dim=-1).mean()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_mpjpe += mpjpe.item() * valid_hands.sum().item()\n",
    "                num_valid += valid_hands.sum().item()\n",
    "            \n",
    "            num_batches += 1\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / max(num_batches, 1),\n",
    "        'mpjpe': total_mpjpe / max(num_valid, 1) if num_valid > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GPU-Only Training\n",
    "print(\"Starting GPU-Only Training with cached dataset...\")\n",
    "print(f\"Batch size: {gpu_config['batch_size']}\")\n",
    "print(f\"Zero CPU operations - everything on GPU!\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create fresh optimizers for GPU-only training\n",
    "gpu_opt_hand = optim.AdamW(hand_encoder.parameters(), lr=2e-3)\n",
    "gpu_opt_object = optim.AdamW(object_encoder.parameters(), lr=2e-3)\n",
    "gpu_opt_contact = optim.AdamW(contact_encoder.parameters(), lr=2e-3)\n",
    "\n",
    "# GPU-only training history\n",
    "gpu_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_mpjpe': [],\n",
    "    'throughput': []\n",
    "}\n",
    "\n",
    "# Initial GPU stats\n",
    "print_gpu_stats()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3  # Quick test\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = gpu_only_train_epoch(\n",
    "        epoch, \n",
    "        hand_encoder, object_encoder, contact_encoder,\n",
    "        gpu_opt_hand, gpu_opt_object, gpu_opt_contact,\n",
    "        gpu_train_loader, gpu_preprocessor\n",
    "    )\n",
    "    gpu_history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = gpu_only_validate(hand_encoder, gpu_val_loader, gpu_preprocessor)\n",
    "    gpu_history['val_loss'].append(val_metrics['loss'])\n",
    "    gpu_history['val_mpjpe'].append(val_metrics['mpjpe'])\n",
    "    \n",
    "    # Calculate throughput\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    total_samples = len(gpu_train_loader) * gpu_config['batch_size']\n",
    "    throughput = total_samples / epoch_time\n",
    "    gpu_history['throughput'].append(throughput)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val MPJPE: {val_metrics['mpjpe']*1000:.2f}mm\")\n",
    "    print(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
    "    print(f\"  Throughput: {throughput:.0f} samples/s\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n",
    "    \n",
    "    # Check GPU utilization\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', \n",
    "                               '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            gpu_util = float(result.stdout.strip())\n",
    "            print(f\"  GPU Utilization: {gpu_util}% {'✓' if gpu_util > 80 else '⚠️'}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\n✓ GPU-Only training completed!\")\n",
    "print_gpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance: Standard vs GPU-Only\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'history' in globals() and 'throughput' in history and len(history['throughput']) > 0:\n",
    "    standard_throughput = np.mean(history['throughput'])\n",
    "    print(f\"Standard DataLoader: {standard_throughput:.0f} samples/s\")\n",
    "else:\n",
    "    print(\"Standard DataLoader: Not run\")\n",
    "\n",
    "if 'gpu_history' in globals() and 'throughput' in gpu_history and len(gpu_history['throughput']) > 0:\n",
    "    gpu_throughput = np.mean(gpu_history['throughput'])\n",
    "    print(f\"GPU-Only Dataset:    {gpu_throughput:.0f} samples/s\")\n",
    "    \n",
    "    if 'standard_throughput' in locals():\n",
    "        speedup = gpu_throughput / standard_throughput\n",
    "        print(f\"\\nSpeedup: {speedup:.1f}x faster with GPU-only approach!\")\n",
    "else:\n",
    "    print(\"GPU-Only Dataset: Not run\")\n",
    "\n",
    "# Plot comparison if both were run\n",
    "if 'history' in globals() and 'gpu_history' in globals():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    if len(history['train_loss']) > 0:\n",
    "        plt.plot(history['train_loss'], label='Standard', marker='o')\n",
    "    if len(gpu_history['train_loss']) > 0:\n",
    "        plt.plot(gpu_history['train_loss'], label='GPU-Only', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if len(history['throughput']) > 0:\n",
    "        plt.bar(['Standard'], [np.mean(history['throughput'])], color='blue', alpha=0.6)\n",
    "    if len(gpu_history['throughput']) > 0:\n",
    "        plt.bar(['GPU-Only'], [np.mean(gpu_history['throughput'])], color='green', alpha=0.6)\n",
    "    plt.ylabel('Samples/second')\n",
    "    plt.title('Throughput Comparison')\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Maximum GPU Utilization\n",
    "\n",
    "### 1. **Adjust Dataset Cache Size**\n",
    "```python\n",
    "# For 140GB H200, you can cache more samples:\n",
    "max_samples_train = 100000  # ~100GB\n",
    "max_samples_train = 150000  # ~150GB (if using bfloat16)\n",
    "```\n",
    "\n",
    "### 2. **Use BFloat16 for More Samples**\n",
    "```python\n",
    "dtype = torch.bfloat16  # Half the memory, similar accuracy\n",
    "```\n",
    "\n",
    "### 3. **Increase Batch Size**\n",
    "```python\n",
    "batch_size = 2048  # or even 4096 if memory allows\n",
    "```\n",
    "\n",
    "### 4. **Monitor GPU Usage**\n",
    "Run in another terminal:\n",
    "```bash\n",
    "watch -n 0.5 nvidia-smi\n",
    "```\n",
    "\n",
    "### 5. **Clear Cache Between Runs**\n",
    "```python\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "```\n",
    "\n",
    "### Expected Results with GPU-Only Approach:\n",
    "- **GPU Utilization**: 90%+ (was 20%)\n",
    "- **Memory Usage**: 50-100GB (was 2.5GB)\n",
    "- **Throughput**: 10,000+ samples/s (was ~500)\n",
    "- **Power Draw**: 600W+ (was 172W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}